

\chapter{问题背景与国内外研究进展}


\section{背景知识概述}

\subsection{矩阵乘法计算及其优化原理}

BLAS三级函数中的通用矩阵乘法(General Purpose Matrix Multiply, GEMM)，是矩阵相乘并累加的运算\cite{UpdatedSetBasic2002}，其基本形式如下所示：

\begin{equation}
     C = \alpha AB + \beta C 
\end{equation}

其中输入矩阵 $A$ 的大小为 $M \times K$，输入矩阵 $B$ 的大小为 $K \times N$，有转置和非转置两种情况，输出矩阵 $C$ 的大小为 $M \times N$。$\alpha$ 和 $\beta$ 为标量，是矩阵乘法的运算系数。矩阵乘法的数据类型可以为，单精度浮点实数，双精度浮点实数，单精度浮点复数，双精度浮点复数等，针对人工智能深度学习领域的计算特点，半精度(half)数据类型，也开始被广泛利用。矩阵乘法的计算复杂度为$O\left(N^3\right)$，访存量为$O\left(N^2\right)$，计算访存比为$O\left(N\right)$，当矩阵的规模较大时，是典型的计算密集型应用。代码\ref{gemmv0}是矩阵乘法算法的一个简单的实现，可以看到矩阵乘法其实是在 M N K 三个维度上的三层嵌套循环，在维度 K 上进行归约和累加的操作。

\begin{lstlisting}[caption=矩阵乘法的简单实现, label=gemmv0]
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            C[i][j] *= beta;
            for (int k = 0; k < K; k++) {
                C[i][j] += alpha * A[i][k] * B[k][j];
            }
        }
    }
\end{lstlisting}

在多核或者众核CPU 上，矩阵乘法优化主要有分块算法、多核并行任务划分、SIMD 向量汇编内核，这三个重要的优化手段。

TODO


TODO 可以提到 winograd 优化方式？


\subsection{申威SW26010P众核处理器}




\subsection{Roofline 模型}

% 首先介绍一下，


\section{国内外研究现状}

申威处理器上存在不少针对 BLAS 算子库的优化工作， 比如[11,12]面向 SW26010-pro 众核处理器探索了 BLAS基础线性代数程序集的高性能实现，充分利用了SW26010-pro 众核处理器的硬件特性。针对异形矩阵乘法，则是需要针对 MNK 三个规模的大小，设计不同的分块，规约方式。

在高性能代码自动生成与自动调优方面,Tensile[13]实现了一套 GPU 汇编 kernel 生成器，定义了一系列和性能相关的 kernel 参数配置，针对固定矩阵规模或一个范围内的矩阵规模，搜索并选择对应性能最好的 kernel。Halide[14]引入了一种可以描述循环优化原语的调度语言。将计算和调度分离，适用于手动优化和自动搜索。Halide有三个基于不同技术的自动调度器版本[15][16][17] 。其中，使用波束搜索和学习成本模型的最新版本表现最好。TVM[18] 使用了类似的调度语言，并包括了一个模板引导搜索框架。而 Ansor[19] 基于 TVM 的框架，针对深度学习工作负载，引入了新的搜索空间，摆脱了对预先定义模版框架的依赖，同时用进化搜索，XGBOOST 筛选器的方式，优化了搜索和自动调优的效率。Ansor 依赖于 LLVM 编译器后端，目前还没有办法直接搜索和生成高性能的汇编 kernel，这是导致他在一些处理器架构上生成 kernel 效率不高的原因之一。而 ukernel[20] 则是实现了一个针对GEMM 汇编 kenrel 的编译器后端。swATOP[21] 在 SW26010-pro 处理器上自动生成 DNN 算子，同样是采用调度器和 IR 优化器的两层架构，并提供自动调优的能力，在 IR 上需要插入调用 DMA 原语，以及 GEMM 原语。

针对矩阵乘法分块参数选择的问题，Le Xu[22]等人，在 SW26010-pro处理器上，首先根据不同循环次序，用公式定义了 DMA 访存量和分块大小 BM、 BN、 BK 之间的关系，以及计算密度和分块大小之间的关系。同时加入最多使用的LDM 大小，和每次DMA或RMA的最小大小作为约束条件。在满足约束条件的情况下，作者训练了一个神经网络，目标函数是最大化计算密度，这样针对某一给定的矩阵计算规模M-N-K，神经网络只需要一次推理的时间就能给出具体的分块参数BM、BN、BK。

TensorIR[23]、GrapheneIR[24]都是针对 Tensor 计算提出了一套中间描述语言IR，然后交给深度学习编译器优化生成高性能的CUDA 程序。TensorIR 使用 block 作为编译器调度的基本单位，block 之间存在消费者和生产者的关系。基于 block 编译器可以调度出软件流水线并且调用 TensorCore 来完成一个 block 的计算任务。GrapheneIR 提供了基于 IR层面的算子融合能力。

多面体编译模型是一种先进的编程优化技术，它能够把程序优化的问题转化为整数线性规划问题。该模型通过对程序中的循环结构进行仿射变换，优化数据的重用策略，从而减少数据处理过程中的时间和空间开销。在申威处理器上，研究者陶小涵[25]等人使用多面体模型[26]，插入各种节点，实现了 GEMM 通用矩阵乘法的自动编译生成，但是缺乏框架的灵活性即自动搜索和调优的能力。

计算图优化是一种将各种计算操作（算子）作为基本处理单元的技术，目的是在保持算子内部结构不变的情况下，对程序的整体计算流程（图）进行优化。这种优化可以通过多种方式实现，包括优化数据布局、合并多个算子以减少操作、折叠固定的常量值、自动化处理数据批次，以及采用不同精度的计算来提高效率。例如，针对海洋模式中求解正压模态的海表高度方，Mindspore[27] 将计算科学代码转换为对应的计算图，自动生成对应的融合算子，例如多个element-wise的算子，减少内存数据的重复搬运。

CUTLASS 是一个由 NVIDIA推出的，基于 C++ 模板特性的矩阵计算库。该数学库利用C++模板来支持灵活的矩阵运算分块策略，和不同矩阵数据精度，例如 int8，int4，FP8 等。基于模块化的理念，CUTLASS 提供了 device level，block level，warp level 等多个层级 api，方便用户使用自定义的算子融合策略。但是，该数学库在使用的时候，往往需要用户来指定分块参数，使得在某些特定的矩阵规模下取得比较好的性能。例如在矩阵 M、N 维度较小的情况下，CUTLASS 需要提供用户手动指定开启 split-k 的优化来提升 SM 的利用率。

综上所述，目前在国产申威 SW26010-pro 处理器上存在不少针对 BLAS 算子库的优化工作，但是仍然有很多的改进的空间。1.胡怡[12]针对了双精度浮点类型较大规模矩阵和异形矩阵的优化，但是针对某个具体规模大小的矩阵乘法问题，在分块参数的选择以及具体算法的选择上，缺乏一定的自适应性，人工手动调优较为耗时。2. 该工作也没有针对单精度，半精度浮点类型的矩阵乘法进行优化。3. 可编程 Cache天然适合利用算子融合的优化来进行加速，但是目前国产申威处理器上的 BLAS库无法很好地利用算子融合来进行加速，需要开发人员手工编写。

因此，本论文研究目标，期望提出一种新的矩阵乘法计算以及代码自动生成框架，能够同时兼容不同的数据类型；针对较大规模矩阵和异形矩阵，具备自动调优，自动搜索的功能；同时基于 DSL 提供算子融合的能力。该计算框架对国产申威众核平台上计算生态的发展有重要意义。

\section{小结}


